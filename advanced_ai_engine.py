"""
Advanced AI Engine for Medical Imaging Diagnosis
Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ø´Ø¹Ø§Ø¹ÙŠ
"""

import torch
import torch.nn as nn
import torchvision.models as models
import numpy as np
import cv2
import streamlit as st
from typing import Dict, Tuple

class AdvancedMedicalCNN(nn.Module):
    """Ù†Ù…ÙˆØ°Ø¬ CNN Ù…ØªÙ‚Ø¯Ù… Ù…ÙØ­Ø³ÙÙ‘Ù† Ù„Ù„ØµÙˆØ± Ø§Ù„Ø·Ø¨ÙŠØ©"""
    
    def __init__(self, num_classes: int = 5):
        super().__init__()
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… ResNet-50 Ù…Ø¹ Ø£ÙˆØ²Ø§Ù† Ù…Ø³Ø¨Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ ImageNet
        self.backbone = models.resnet50(pretrained=True)
        
        # ØªØ¬Ù…ÙŠØ¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        for param in list(self.backbone.parameters())[:-20]:
            param.requires_grad = False
        
        # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ø¨ØªØµÙ…ÙŠÙ… Ù…ÙØ­Ø³ÙÙ‘Ù†
        in_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Sequential(
            nn.Dropout(0.4),
            nn.Linear(in_features, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(256, num_classes)
        )
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø£ÙˆØ²Ø§Ù†
        self._initialize_weights()
    
    def _initialize_weights(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Kaiming Initialization"""
        for m in self.backbone.fc.modules():
            if isinstance(m, nn.Linear):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.backbone(x)

class MedicalVisionTransformer(nn.Module):
    """Ù…Ø­ÙˆÙ„ Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„Ù…ÙØ­Ø³ÙÙ‘Ù† Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠ"""
    
    def __init__(self, image_size: int = 224, patch_size: int = 16, num_classes: int = 5, 
                 dim: int = 768, depth: int = 6, heads: int = 8):
        super().__init__()
        
        self.image_size = image_size
        self.patch_size = patch_size
        self.num_patches = (image_size // patch_size) ** 2
        
        # Ø·Ø¨Ù‚Ø© Ø¥Ø³Ù‚Ø§Ø· Ø§Ù„Ø±Ù‚Ø¹
        self.patch_embed = nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size)
        
        # Ù…ÙˆØ¶Ø¹ÙŠ embeddings
        self.pos_embed = nn.Parameter(torch.randn(1, self.num_patches + 1, dim))
        
        # Ø·Ø¨Ù‚Ø© Ø§Ù„ØµÙ†Ù
        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))
        
        # Ù…Ø­ÙˆÙ„ encoder
        encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=heads, 
                                                 dim_feedforward=dim*4, dropout=0.1)
        self.transformer = nn.TransformerEncoder(encoder_layer, depth)
        
        # Ù…ØµÙ†Ù
        self.mlp_head = nn.Sequential(
            nn.LayerNorm(dim),
            nn.Linear(dim, num_classes)
        )
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        B, C, H, W = x.shape
        
        # ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø±Ù‚Ø¹
        x = self.patch_embed(x)
        x = x.flatten(2).transpose(1, 2)
        
        # Ø¥Ø¶Ø§ÙØ© token Ø§Ù„ØµÙ†Ù
        cls_tokens = self.cls_token.expand(B, -1, -1)
        x = torch.cat((cls_tokens, x), dim=1)
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ÙˆØ¶Ø¹ÙŠ embeddings
        x += self.pos_embed
        
        # Ù…Ø­ÙˆÙ„
        x = self.transformer(x)
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… token Ø§Ù„ØµÙ†Ù ÙÙ‚Ø· Ù„Ù„ØªØµÙ†ÙŠÙ
        x = x[:, 0]
        
        return self.mlp_head(x)

class HybridMedicalAI(nn.Module):
    """Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù‡Ø¬ÙŠÙ† Ø§Ù„Ù…ØªÙ‚Ø¯Ù…: CNN + Vision Transformer"""
    
    def __init__(self, num_classes: int = 5):
        super().__init__()
        
        self.cnn_branch = AdvancedMedicalCNN(num_classes)
        self.vit_branch = MedicalVisionTransformer(num_classes=num_classes)
        
        # Ø·Ø¨Ù‚Ø© Ø§Ù†Ø¯Ù…Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª
        self.feature_fusion = nn.Sequential(
            nn.Linear(num_classes * 2, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )
        
        # Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ù„ÙˆØ²Ù† Ø§Ù„ÙØ±ÙˆØ¹
        self.branch_attention = nn.Linear(num_classes * 2, 2)
    
    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        # Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„ÙØ±ÙˆØ¹
        cnn_out = self.cnn_branch(x)
        vit_out = self.vit_branch(x)
        
        # Ø§Ù†Ø¯Ù…Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª
        combined = torch.cat([cnn_out, vit_out], dim=1)
        
        # Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ù„Ù„ÙØ±ÙˆØ¹
        attention_weights = torch.softmax(self.branch_attention(combined), dim=1)
        
        # Ø§Ù„Ø§Ù†Ø¯Ù…Ø§Ø¬ Ø§Ù„Ù…Ø±Ø¬Ø­
        weighted_cnn = cnn_out * attention_weights[:, 0:1]
        weighted_vit = vit_out * attention_weights[:, 1:2]
        
        # Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        final_output = self.feature_fusion(combined)
        
        return {
            'final_prediction': final_output,
            'cnn_output': cnn_out,
            'vit_output': vit_out,
            'attention_weights': attention_weights,
            'confidence': torch.softmax(final_output, dim=1).max(dim=1)[0]
        }

def enhance_medical_image(image: np.ndarray) -> np.ndarray:
    """
    ØªØ­Ø³ÙŠÙ† Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ØµÙˆØ± Ø§Ù„Ø·Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
    """
    if len(image.shape) == 3:
        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    
    # 1. Ø§Ù„Ù…ÙˆØ§Ø²Ù†Ø© Ø§Ù„ØªÙƒÙŠÙÙŠØ© Ù„Ù„ØªØ¨Ø§ÙŠÙ† (CLAHE)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(image)
    
    # 2. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ ØºÙŠØ± Ø§Ù„Ù…Ø­Ù„ÙŠØ©
    denoised = cv2.fastNlMeansDenoising(enhanced, h=15, templateWindowSize=7, searchWindowSize=21)
    
    # 3. ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ø¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø±Ø´Ø­ unsharp masking
    gaussian = cv2.GaussianBlur(denoised, (0, 0), 2.0)
    sharpened = cv2.addWeighted(denoised, 1.5, gaussian, -0.5, 0)
    
    # 4. Ø§Ù„Ù…ÙˆØ§Ø²Ù†Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø´Ø¯Ø©
    normalized = cv2.normalize(sharpened, None, 0, 255, cv2.NORM_MINMAX)
    
    return normalized

class MedicalAIManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø·Ø¨ÙŠ Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
    
    def __init__(self):
        self.model = HybridMedicalAI()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©
        self._setup_pretrained_weights()
    
    def _setup_pretrained_weights(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø£ÙˆØ²Ø§Ù† Ù…Ø¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹ (Ù…Ø­Ø§ÙƒØ§Ø© Ù„Ù„Ø¹Ø±Ø¶)"""
        try:
            # ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØŒ Ø³ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©
            st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù‡Ø¬ÙŠÙ† Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¨Ù†Ø¬Ø§Ø­")
        except:
            st.info("ğŸ”§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ - Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ¯Ø±ÙŠØ¨")
    
    def predict(self, image: np.ndarray) -> Dict:
        """ØªÙ†Ø¨Ø¤ Ù…ØªÙ‚Ø¯Ù… Ø¨Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·Ø¨ÙŠØ©"""
        try:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù„Ù„ØµÙˆØ±Ø©
            processed_image = self._preprocess_image(image)
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ tensor
            input_tensor = torch.FloatTensor(processed_image).unsqueeze(0).to(self.device)
            
            # ÙˆØ¶Ø¹ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
            self.model.eval()
            with torch.no_grad():
                outputs = self.model(input_tensor)
            
            return self._format_predictions(outputs, image)
            
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤: {str(e)}")
            return self._get_fallback_prediction()
    
    def _preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„ØµÙˆØ±Ø©"""
        # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©
        enhanced = enhance_medical_image(image)
        
        # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù…
        resized = cv2.resize(enhanced, (224, 224))
        
        # Ø§Ù„ØªØ·Ø¨ÙŠØ¹
        normalized = resized / 255.0
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ 3 Ù‚Ù†ÙˆØ§Øª Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø© Ø¹Ù„Ù‰ ImageNet
        if len(normalized.shape) == 2:
            normalized = np.stack([normalized] * 3, axis=2)
        
        # Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: (H, W, C) -> (C, H, W)
        normalized = np.transpose(normalized, (2, 0, 1))
        
        return normalized
    
    def _format_predictions(self, outputs: Dict, original_image: np.ndarray) -> Dict:
        """ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ù„Ø¹Ø±Ø¶Ù‡Ø§"""
        final_pred = torch.softmax(outputs['final_prediction'], dim=1)
        confidence, predicted_class = torch.max(final_pred, 1)
        
        # Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªØ´Ø®ÙŠØµØ§Øª
        diagnosis_map = {
            0: "Normal Tissue",
            1: "Benign Lesion", 
            2: "Suspicious Abnormality",
            3: "Malignant Indication",
            4: "Artifact/Noise"
        }
        
        # Ø®Ø±ÙŠØ·Ø© Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø®Ø·ÙˆØ±Ø©
        risk_map = {
            0: "Very Low",
            1: "Low",
            2: "Medium", 
            3: "High",
            4: "Critical"
        }
        
        return {
            'primary_diagnosis': diagnosis_map[predicted_class.item()],
            'confidence': confidence.item(),
            'risk_level': risk_map[predicted_class.item()],
            'differential_diagnosis': self._get_differential_diagnosis(final_pred[0]),
            'attention_weights': outputs['attention_weights'].cpu().numpy()[0],
            'branch_contributions': {
                'cnn_confidence': torch.softmax(outputs['cnn_output'], dim=1).max().item(),
                'vit_confidence': torch.softmax(outputs['vit_output'], dim=1).max().item()
            },
            'recommendations': self._generate_recommendations(predicted_class.item(), confidence.item())
        }
    
    def _get_differential_diagnosis(self, probabilities: torch.Tensor) -> list:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„ØªÙØ±ÙŠÙ‚ÙŠ"""
        diagnoses = ["Normal", "Benign", "Suspicious", "Malignant", "Artifact"]
        top3 = torch.topk(probabilities, 3)
        
        return [
            {
                'diagnosis': diagnoses[i],
                'probability': f"{p.item():.3f}",
                'percentage': f"{p.item()*100:.1f}%"
            }
            for p, i in zip(top3.values, top3.indices)
        ]
    
    def _generate_recommendations(self, diagnosis_class: int, confidence: float) -> list:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø³Ø±ÙŠØ±ÙŠØ© Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„ØªØ´Ø®ÙŠØµ"""
        base_recommendations = {
            0: ["Routine follow-up as per standard protocol", "No immediate intervention required"],
            1: ["Short-term follow-up recommended (3-6 months)", "Consider additional imaging if symptomatic"],
            2: ["Further diagnostic workup advised", "Multidisciplinary consultation recommended", "Consider biopsy if clinically indicated"],
            3: ["Urgent specialist referral required", "Immediate diagnostic intervention needed", "Multidisciplinary tumor board review"],
            4: ["Repeat imaging study recommended", "Technical factors should be reviewed", "Consider alternative imaging modality"]
        }
        
        recommendations = base_recommendations.get(diagnosis_class, [])
        
        # Ø¥Ø¶Ø§ÙØ© ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©
        if confidence < 0.7:
            recommendations.append("Low confidence prediction - clinical correlation strongly advised")
        elif confidence > 0.9:
            recommendations.append("High confidence prediction - proceed with clinical management")
        
        return recommendations
    
    def _get_fallback_prediction(self) -> Dict:
        """ØªÙ†Ø¨Ø¤ Ø§Ø­ØªÙŠØ§Ø·ÙŠ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„"""
        return {
            'primary_diagnosis': "Analysis Inconclusive",
            'confidence': 0.0,
            'risk_level': "Unknown",
            'differential_diagnosis': [],
            'recommendations': ["Repeat image analysis", "Consult clinical findings", "Consider alternative imaging"]
        }

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ
@st.cache_resource
def load_medical_ai_model():
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
    st.info("ğŸš€ Loading Advanced Hybrid Medical AI Model...")
    return MedicalAIManager()

if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø­Ø±Ùƒ
    model = load_medical_ai_model()
    st.success("âœ… Advanced Medical AI Engine is ready for deployment!")
